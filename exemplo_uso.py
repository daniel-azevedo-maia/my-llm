"""
Arquivo de Exemplo e Demonstra√ß√£o
Este arquivo mostra como usar o Sistema LLM Local programaticamente
"""

from document_processor import DocumentProcessor
from llm_system import LocalLLM, LLMTrainer

def exemplo_basico():
    """Exemplo b√°sico de uso do sistema"""
    print("ü§ñ Exemplo de Uso do Sistema LLM Local")
    print("=" * 40)
    
    # Inicializa sistema
    print("1. Inicializando sistema...")
    llm = LocalLLM()
    trainer = LLMTrainer(llm)
    
    # Adiciona documento
    print("2. Adicionando documento de teste...")
    success = trainer.train_with_document("documento_teste.txt")
    print(f"   Resultado: {'‚úÖ Sucesso' if success else '‚ùå Falha'}")
    
    # Mostra estat√≠sticas
    print("3. Estat√≠sticas do conhecimento:")
    stats = llm.get_knowledge_stats()
    for key, value in stats.items():
        print(f"   {key}: {value}")
    
    # Simula perguntas (sem Ollama rodando, apenas mostra estrutura)
    print("4. Exemplos de perguntas que funcionariam:")
    perguntas = [
        "Qual √© o tema principal do documento?",
        "Como usar o sistema?",
        "Quais formatos s√£o suportados?",
        "Resuma as caracter√≠sticas principais"
    ]
    
    for pergunta in perguntas:
        print(f"   üë§ {pergunta}")
        # Aqui seria: resposta = llm.generate_response(pergunta)
        print(f"   ü§ñ [Resposta seria gerada aqui com Ollama rodando]")
        print()

def exemplo_processamento_documentos():
    """Exemplo de processamento de m√∫ltiplos documentos"""
    print("\nüìö Exemplo de Processamento de Documentos")
    print("=" * 45)
    
    processor = DocumentProcessor("exemplo_kb")
    
    # Lista de documentos exemplo
    documentos = ["documento_teste.txt"]
    
    for doc in documentos:
        print(f"Processando: {doc}")
        
        def callback(msg):
            print(f"  üìù {msg}")
        
        success = processor.process_document(doc, callback)
        print(f"  {'‚úÖ' if success else '‚ùå'} Resultado: {success}")
    
    # Testa busca
    print("\nüîç Testando busca:")
    resultados = processor.search_knowledge("sistema LLM")
    
    for i, resultado in enumerate(resultados[:2]):  # Mostra apenas 2
        print(f"  Resultado {i+1}:")
        print(f"    Arquivo: {resultado['filename']}")
        print(f"    Relev√¢ncia: {resultado['relevance_score']:.2f}")
        print(f"    Trecho: {resultado['content'][:100]}...")
        print()

def exemplo_interface_programatica():
    """Exemplo de como usar sem interface gr√°fica"""
    print("\nüíª Exemplo de Uso Program√°tico")
    print("=" * 35)
    
    # C√≥digo que o usu√°rio poderia usar
    codigo_exemplo = '''
# Importa o sistema
from llm_system import LocalLLM

# Inicializa
llm = LocalLLM()

# Configura sistema (primeira vez)
llm.setup_system()

# Adiciona documento
llm.add_document("meu_documento.pdf")

# Faz pergunta
resposta = llm.generate_response("Qual √© o tema principal?")
print(resposta)

# Limpa conhecimento se necess√°rio
llm.clear_knowledge()
'''
    
    print("C√≥digo de exemplo:")
    print(codigo_exemplo)

if __name__ == "__main__":
    try:
        exemplo_basico()
        exemplo_processamento_documentos()
        exemplo_interface_programatica()
        
        print("\nüéâ Todos os exemplos executados com sucesso!")
        print("\nPara usar com interface gr√°fica, execute: python main.py")
        
    except Exception as e:
        print(f"\n‚ùå Erro durante execu√ß√£o: {e}")
        print("Verifique se todas as depend√™ncias est√£o instaladas.")

